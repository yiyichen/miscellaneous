{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to retrain the NLTK backoff tagger.\n",
    "- You'll see an example in which some recipe text has some errors in tagging, most likely because the training data did not have many examples of the target sentence structure.  \n",
    "- Next, you'll see the affects of adding a few sentences of training data with the missing sentence structure on the accuracy of the tagger.\n",
    "- Your assignment is to do something similar on your adopted text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import brown\n",
    "from nltk import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for training and evaluating a backoff tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_data_sets(sentences):\n",
    "    size = int(len(sentences) * 0.9)\n",
    "    train_sents = sentences[:size]\n",
    "    test_sents = sentences[size:]\n",
    "    return train_sents, test_sents\n",
    "\n",
    "def build_backoff_tagger (train_sents):\n",
    "    t0 = nltk.DefaultTagger('NN')\n",
    "    t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "    t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "    return t2\n",
    "\n",
    "def train_tagger(already_tagged_sents):\n",
    "    train_sents, test_sents = create_data_sets(already_tagged_sents)\n",
    "    ngram_tagger = build_backoff_tagger(train_sents)\n",
    "    print (\"%0.3f pos accuracy on test set\" % ngram_tagger.evaluate(test_sents))\n",
    "    return ngram_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a specialized function for training a tagger on the brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tagger_on_brown():\n",
    "    brown_tagged_sents = brown.tagged_sents(categories=['adventure', 'belles_lettres', 'editorial', \n",
    "                                                        'fiction', 'government', 'hobbies', 'humor', \n",
    "                                                        'learned', 'lore', 'mystery', 'religion', \n",
    "                                                        'reviews', 'romance','science_fiction'])\n",
    "    return train_tagger(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for creating an NLTK corpus object, so we can operate on it using nltk.tokenize_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_text(corpus):\n",
    "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sents = sent_tokenizer.tokenize(corpus) # Split text into sentences    \n",
    "    return [nltk.word_tokenize(word) for word in raw_sents]\n",
    "\n",
    "def create_corpus(f):\n",
    "    with open(f, 'r') as text_file:\n",
    "        new_corpus = text_file.read()\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train and evaluate an ngram backoff tagger, using the brown corpus as the training and testing set.  (This takes a few moments to complete.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911 pos accuracy on test set\n"
     ]
    }
   ],
   "source": [
    "brown_tagger = train_tagger_on_brown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, read in a file of recipes and tokenize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cookbook_file = './cookbooks.txt'\n",
    "# cookbook_sents = tokenize_text(create_corpus(cookbook_file))\n",
    "\n",
    "novel_file = '../1984.rtf'\n",
    "content = create_corpus(novel_file)\n",
    "content = content.replace(\"\\\\par\", \"\")\n",
    "content = content.replace(\"&\", \"and\")\n",
    "content = content[171:]\n",
    "novel_sents = tokenize_text(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cooking recipe collection,  imperative sentences (sentences that being with a verb) are always mistagged.  The POS tagger marks the initial verb as NN instead of VB.  (There may be other kinds of errors too, but we are only looking at imperative sentences here.) In order to see the sentences where the errors are occuring, the code below finds sentences that begin with imperatives, tags them with the tagger, and returns them in a list. \n",
    "\n",
    "> YC: In the 1984 text collection, contractions such as I'm and you'll are mistagged. The POS tagger marks the \"'m\" and \"'ll\" as NN instead of BEM and MD. Additionally novel specific word like \"Thought Police\" got mistagged, where \"Thought\" was taken as VBD instead of NN.  \n",
    "\n",
    "> The code below - \n",
    "> 1. get_tag_novel: return tagged sentences with the supplied tagger. It takes in an optional input of a single token string. If a token is provided, only sentences containing that token will be returned.\n",
    "> 2. select_random_sent: select and print n sentences from the list of tagged sentences for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_cookbook_imperatives(sents, tagger):\n",
    "#     cooking_commands = [\"Wash\", \"Stir\", \"Moisten\", \"Drain\", \"Cook\", \"Pour\", \"Chop\", \n",
    "#                         \"Slice\", \"Season\", \"Mix\", \"Fry\", \"Bake\", \"Roast\", \"Wisk\"]        \n",
    "#     return [tagger.tag(sent) for sent in sents if sent[0] in cooking_commands]  \n",
    "\n",
    "def get_tag_novel (sents, tagger, identifier = None):     \n",
    "    if identifier == None: return [tagger.tag(sent) for sent in sents]\n",
    "    else: return [tagger.tag(sent) for sent in sents if identifier in sent]\n",
    "\n",
    "def select_random_sent(tagged_sents, n):\n",
    "    num_sents = len(tagged_sents)\n",
    "    num_sim = n if num_sents > n else num_sents\n",
    "    random_idx = random.sample(range(num_sents), num_sim)\n",
    "    selected_sents = [tagged_sents[i] for i in random_idx]\n",
    "    for i in range(num_sim):\n",
    "        print(\"sentence #:\", random_idx[i])\n",
    "        print(\"tags: \", selected_sents[i], end = \" \")\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at those sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Contractions ==========\n",
      "Example 1: 'm in I'm incorrectly tagged. Examples are shown below: \n",
      "sentence #: 19\n",
      "tags:  [('On', 'IN'), ('the', 'AT'), ('whole', 'JJ'), ('I', 'PPSS'), (\"'m\", 'NN'), ('sorry', 'JJ'), ('I', 'PPSS'), ('did', 'DOD'), (\"n't\", 'NN'), ('.', '.'), (\"'\", \"'\")] \n",
      "\n",
      "\n",
      "sentence #: 1\n",
      "tags:  [('I', 'PPSS'), (\"'m\", 'NN'), ('too', 'QL'), ('busy', 'JJ'), ('to', 'TO'), ('take', 'VB'), ('them', 'PPO'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 24\n",
      "tags:  [('In', 'IN'), ('this', 'DT'), ('room', 'NN'), ('I', 'PPSS'), (\"'m\", 'NN'), ('going', 'VBG'), ('to', 'TO'), ('be', 'BE'), ('a', 'AT'), ('woman', 'NN'), (',', ','), ('not', '*'), ('a', 'AT'), ('Party', 'NN-TL'), ('comrade', 'NN'), ('.', '.'), (\"'\", \"'\")] \n",
      "\n",
      "\n",
      "\n",
      "========== Contractions ==========\n",
      "Example 2: 'll in you'll incorrectly tagged. Examples are shown below: \n",
      "sentence #: 1\n",
      "tags:  [('but', 'CC'), ('in', 'IN'), ('the', 'AT'), ('final', 'JJ'), ('version', 'NN'), ('of', 'IN'), ('Newspeak', 'NN'), ('there', 'EX'), (\"'ll\", 'NN'), ('be', 'BE'), ('nothing', 'PN'), ('else', 'RB'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 27\n",
      "tags:  [('Give', 'VB'), ('me', 'PPO'), ('a', 'AT'), ('chance', 'NN'), ('and', 'CC'), ('I', 'PPSS'), (\"'ll\", 'NN'), ('tell', 'VB'), ('you', 'PPO'), ('every', 'AT'), ('word', 'NN'), ('of', 'IN'), ('it', 'PPO'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 17\n",
      "tags:  [(\"'I\", 'NN'), (\"'ll\", 'NN'), ('take', 'VB'), ('it', 'PPO'), ('down', 'RP'), ('and', 'CC'), ('give', 'VB'), ('it', 'PPO'), ('a', 'AT'), ('good', 'JJ'), ('clean', 'JJ'), ('some', 'DTI'), ('day', 'NN'), ('.', '.')] \n",
      "\n",
      "\n",
      "\n",
      "========== Past Tense as Noun ==========\n",
      "Thought in Thought Process incorrectly tagged. Examples are shown below: \n",
      "sentence #: 28\n",
      "tags:  [('It', 'PPS'), ('is', 'BEZ'), ('not', '*'), ('simply', 'RB'), ('an', 'AT'), ('invention', 'NN'), ('of', 'IN'), ('the', 'AT'), ('Thought', 'VBD'), ('Police', 'NNS-TL'), ('?', '.'), (\"'\", \"'\")] \n",
      "\n",
      "\n",
      "sentence #: 12\n",
      "tags:  [('Within', 'IN'), ('2', 'CD'), ('years', 'NNS'), ('those', 'DTS'), ('children', 'NNS'), ('would', 'MD'), ('be', 'BE'), ('denouncing', 'VBG'), ('her', 'PP$'), ('to', 'TO'), ('the', 'AT'), ('Thought', 'VBD'), ('Police', 'NNS-TL'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 23\n",
      "tags:  [('If', 'CS'), ('you', 'PPSS'), ('really', 'RB'), ('want', 'VB'), ('to', 'TO'), ('know', 'VB'), (',', ','), ('I', 'PPSS'), ('imagined', 'VBD'), ('that', 'CS'), ('you', 'PPSS'), ('had', 'HVD'), ('something', 'PN'), ('to', 'TO'), ('do', 'DO'), ('with', 'IN'), ('the', 'AT'), ('Thought', 'VBD'), ('Police', 'NNS-TL'), ('.', '.'), (\"'\", \"'\")] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imperatives = get_cookbook_imperatives(cookbook_sents, brown_tagger)\n",
    "# imperatives[:5]\n",
    "\n",
    "print(\"========== Contractions ==========\")\n",
    "print(\"Example 1: 'm in I'm incorrectly tagged. Examples are shown below: \")\n",
    "novel_tags_problematic = get_tag_novel(novel_sents, brown_tagger, \"'m\")\n",
    "select_random_sent(novel_tags_problematic, 3)\n",
    "print()\n",
    "\n",
    "print(\"========== Contractions ==========\")\n",
    "print(\"Example 2: 'll in you'll incorrectly tagged. Examples are shown below: \")\n",
    "novel_tags_problematic = get_tag_novel(novel_sents, brown_tagger, \"'ll\")\n",
    "select_random_sent(novel_tags_problematic, 3)\n",
    "print()\n",
    "\n",
    "print(\"========== Past Tense as Noun ==========\")\n",
    "print(\"Thought in Thought Process incorrectly tagged. Examples are shown below: \")\n",
    "novel_tags_problematic = get_tag_novel(novel_sents, brown_tagger, \"Thought\")\n",
    "select_random_sent(novel_tags_problematic, 3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that most of the initial words are incorrectly tagged as nouns rather than verbs.  How can we fix this?  One way is to label a few rather generic sentences with the structure we are interested in, add them to the start of the training data, and then retrain the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keeping this for better continuity\n",
    "def train_tagger_on_brown_augmented_with_cooking_sents():\n",
    "\n",
    "    cooking_action_sents = [[('Strain', 'VB'), ('it', 'PPS'), ('well', 'RB'), ('.', '.')],\n",
    "                        [('Mix', 'VB'), ('them', 'PPS'), ('well', 'RB'), ('.', '.')],\n",
    "                        [('Season', 'VB'), ('them', 'PPS'), ('with', 'IN'), ('pepper', 'NN'), ('.', '.')], \n",
    "                        [('Wash', 'VB'), ('it', 'PPS'), ('well', 'RB'), ('.', '.')],\n",
    "                        [('Chop', 'VB'), ('the', 'AT'), ('greens', 'NNS'), ('.', '.')],\n",
    "                        [('Slice', 'VB'), ('it', 'PPS'), ('well', 'RB'), ('.', '.')],\n",
    "                        [('Bake', 'VB'), ('the', 'AT'), ('cake', 'NN'), ('.', '.')],\n",
    "                        [('Pour', 'VB'), ('into', 'IN'), ('a', 'AT'), ('mold', 'NN'), ('.', '.')],\n",
    "                        [('Stir', 'VB'), ('the', 'AT'), ('mixture', 'NN'), ('.', '.')],\n",
    "                        [('Moisten', 'VB'), ('the', 'AT'), ('grains', 'NNS'), ('.', '.')],\n",
    "                        [('Cook', 'VB'), ('the', 'AT'), ('duck', 'NN'), ('.', '.')],\n",
    "                        [('Drain', 'VB'), ('for', 'IN'), ('one', 'CD'), ('day', 'NN'), ('.', '.')]]\n",
    "\n",
    "\n",
    "    brown_tagged_sents = brown.tagged_sents(categories=['adventure', 'belles_lettres', 'editorial', \n",
    "                                                        'fiction', 'government', 'hobbies', 'humor', \n",
    "                                                        'learned', 'lore', 'mystery', 'religion', \n",
    "                                                        'reviews', 'romance', 'science_fiction'])\n",
    "    \n",
    "    #append hand-tagged cooking sentences to the front of the training data\n",
    "    all_tagged_sents = cooking_action_sents + brown_tagged_sents\n",
    "    return train_tagger(all_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> YC: Following the same method as above, retrain the model with example sentences with desirable structures and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tagger_on_brown_augmented_with_novel_sents():\n",
    "\n",
    "    contraction_sents = [[('I', 'PPSS'), (\"'m\", 'BEM'), ('well', 'RB'), ('.', '.')],\n",
    "                        [('I', 'PPSS'), (\"'m\", 'BEM'), ('not', '*'), ('very', 'QL'), ('sure', 'JJ'), ('.', '.')],\n",
    "                        [('I', 'PPSS'), (\"'m\", 'BEM'), ('interested', 'VBN'), ('.', '.')],\n",
    "                        [('I', 'PPSS'), (\"'m\", 'BEM'), ('a', 'AT'), ('person', 'NN'), ('.', '.')],\n",
    "                        [('You', 'PPSS'), (\"'ll\", 'MD'), ('learn', 'VB'), ('.', '.')], \n",
    "                        [('You', 'PPSS'), (\"'ll\", 'MD'), ('give', 'VB'), ('me', 'PPO'), ('a', 'AT'), ('chance', 'NN')],\n",
    "                        [('She', 'PPS'), (\"'ll\", 'MD'), ('never', 'RB'), ('do', 'VB'), ('that', 'CS'), ('.', '.')]]\n",
    "    \n",
    "    thought_as_noun = [[('Who', 'WPS'), (\"is\", 'BEZ'), ('the', 'AT'), ('Thought', 'NN'), ('Police', 'NN')],\n",
    "                       [('I', 'PPSS'), (\"avoid\", 'VB'), ('the', 'AT'), ('Thought', 'NN'), ('Police', 'NN')],\n",
    "                       [('The', 'AT'), (\"Thought\", 'NN'), ('Police', 'NN'), ('is', 'BEZ'), ('everywhere', 'RB')]]\n",
    "                        \n",
    "\n",
    "    brown_tagged_sents = brown.tagged_sents(categories=['adventure', 'belles_lettres', 'editorial', \n",
    "                                                        'fiction', 'government', 'hobbies', 'humor', \n",
    "                                                        'learned', 'lore', 'mystery', 'religion', \n",
    "                                                        'reviews', 'romance', 'science_fiction'])\n",
    "    \n",
    "    #append hand-tagged cooking sentences to the front of the training data\n",
    "    all_tagged_sents = contraction_sents + thought_as_noun + brown_tagged_sents\n",
    "    return train_tagger(all_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911 pos accuracy on test set\n"
     ]
    }
   ],
   "source": [
    "# brown_and_cooking_tagger = train_tagger_on_brown_augmented_with_cooking_sents()\n",
    "\n",
    "brown_and_novel_tagger = train_tagger_on_brown_augmented_with_novel_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well is this working on the cookbook imperatives now? Is more training data needed to change the behavior of the tagger? \n",
    "\n",
    "> YC: The cookbook imperatives are improved. So are the contractions and special nouns for the novel 1984!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Contractions ==========\n",
      "Example 1: 'm in I'm incorrectly tagged. Corrected by improved tagger: \n",
      "sentence #: 6\n",
      "tags:  [(\"'and\", 'NN'), ('was', 'BEDZ'), ('it', 'PPS'), ('usual', 'JJ'), ('-', 'IN'), ('I', 'PPSS-NC'), (\"'m\", 'BEM'), ('only', 'RB'), ('quoting', 'VBG'), ('what', 'WDT'), ('I', 'PPSS'), (\"'ve\", 'NN'), ('read', 'VBN'), ('in', 'IN'), ('history', 'NN'), ('books', 'NNS'), ('-', 'IN'), ('was', 'BEDZ'), ('it', 'PPS'), ('usual', 'JJ'), ('for', 'IN'), ('these', 'DTS'), ('people', 'NNS'), ('and', 'CC'), ('their', 'PP$'), ('servants', 'NNS'), ('to', 'TO'), ('push', 'VB'), ('you', 'PPO'), ('off', 'RP'), ('the', 'AT'), ('pavement', 'NN'), ('into', 'IN'), ('the', 'AT'), ('gutter', 'NN'), ('?', '.'), (\"'\", \"'\")] \n",
      "\n",
      "\n",
      "sentence #: 29\n",
      "tags:  [(\"'I\", 'NN'), (\"'m\", 'BEM'), ('only', 'RB'), ('an', 'AT'), ('amateur', 'NN'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 39\n",
      "tags:  [('``', '``'), ('Thank', 'VB'), ('you', 'PPO'), (',', ','), (\"''\", \"''\"), ('I', 'PPSS'), (\"'m\", 'BEM'), ('going', 'VBG'), ('to', 'TO'), ('say', 'VB'), (',', ','), ('``', '``'), ('thank', 'VB'), ('you', 'PPO'), ('for', 'IN'), ('saving', 'VBG'), ('me', 'PPO'), ('before', 'RB'), ('it', 'PPS'), ('was', 'BEDZ'), ('too', 'QL'), ('late', 'JJ'), ('.', '.'), (\"''\", \"''\")] \n",
      "\n",
      "\n",
      "\n",
      "========== Contractions ==========\n",
      "Example 2: 'll in you'll incorrectly tagged. Corrected by improved tagger: \n",
      "sentence #: 15\n",
      "tags:  [('I', 'PPSS'), (\"'ll\", 'MD'), ('stuff', 'VB'), ('the', 'AT'), ('hole', 'NN'), ('with', 'IN'), ('a', 'AT'), ('bit', 'NN'), ('of', 'IN'), ('sacking', 'NN'), ('before', 'IN'), ('we', 'PPSS'), ('go', 'VB'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 3\n",
      "tags:  [('Smith', 'NP'), (',', ','), ('old', 'JJ'), ('boy', 'NN'), (',', ','), ('I', 'PPSS'), (\"'ll\", 'MD'), ('tell', 'VB'), ('you', 'PPO'), ('why', 'WRB'), ('I', 'PPSS'), (\"'m\", 'BEM'), ('chasing', 'VBG'), ('you', 'PPO'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 23\n",
      "tags:  [('Just', 'RB'), ('tell', 'VB'), ('me', 'PPO'), ('what', 'WDT'), ('it', 'PPS'), ('is', 'BEZ'), ('and', 'CC'), ('I', 'PPSS'), (\"'ll\", 'MD'), ('confess', 'VB'), ('straight', 'RB'), ('off', 'IN'), ('.', '.')] \n",
      "\n",
      "\n",
      "\n",
      "========== Past Tense as Noun ==========\n",
      "Thought in Thought Process incorrectly tagged. Corrected by improved tagger: \n",
      "sentence #: 16\n",
      "tags:  [('No', 'AT'), ('one', 'CD'), ('who', 'WPS'), ('had', 'HVD'), ('once', 'RB'), ('fallen', 'VBN'), ('into', 'IN'), ('the', 'AT'), ('hands', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('Thought', 'NN'), ('Police', 'NN'), ('ever', 'RB'), ('escaped', 'VBN'), ('in', 'IN'), ('the', 'AT'), ('end', 'NN'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 18\n",
      "tags:  [('Whether', 'CS'), ('she', 'PPS'), ('was', 'BEDZ'), ('really', 'RB'), ('an', 'AT'), ('agent', 'NN'), ('of', 'IN'), ('the', 'AT'), ('Thought', 'NN'), ('Police', 'NN'), (',', ','), ('or', 'CC'), ('simply', 'RB'), ('an', 'AT'), ('amateur', 'NN'), ('spy', 'NN'), ('actuated', 'VBN'), ('by', 'IN'), ('officiousness', 'NN'), (',', ','), ('hardly', 'RB'), ('mattered', 'VBD'), ('.', '.')] \n",
      "\n",
      "\n",
      "sentence #: 27\n",
      "tags:  [('In', 'IN'), ('a', 'AT'), ('way', 'NN'), ('she', 'PPS'), ('realized', 'VBD'), ('that', 'CS'), ('she', 'PPS'), ('herself', 'PPL'), ('was', 'BEDZ'), ('doomed', 'VBD'), (',', ','), ('that', 'CS'), ('sooner', 'RBR'), ('or', 'CC'), ('later', 'RBR'), ('the', 'AT'), ('Thought', 'NN'), ('Police', 'NN'), ('would', 'MD'), ('catch', 'VB'), ('her', 'PPO'), ('and', 'CC'), ('kill', 'VB'), ('her', 'PPO'), (',', ','), ('but', 'CC'), ('with', 'IN'), ('another', 'DT'), ('part', 'NN'), ('of', 'IN'), ('her', 'PP$'), ('mind', 'NN'), ('she', 'PPS'), ('believed', 'VBD'), ('that', 'CS'), ('it', 'PPS'), ('was', 'BEDZ'), ('somehow', 'RB'), ('possible', 'JJ'), ('to', 'TO'), ('construct', 'VB'), ('a', 'AT'), ('secret', 'NN'), ('world', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('you', 'PPSS'), ('could', 'MD'), ('live', 'VB'), ('as', 'CS'), ('you', 'PPSS'), ('chose', 'VBD'), ('.', '.')] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# better_imperatives = get_cookbook_imperatives(cookbook_sents, brown_and_cooking_tagger)\n",
    "# better_imperatives[:5]\n",
    "\n",
    "print(\"========== Contractions ==========\")\n",
    "print(\"Example 1: 'm in I'm incorrectly tagged. Corrected by improved tagger: \")\n",
    "novel_tags_better = get_tag_novel(novel_sents, brown_and_novel_tagger, \"'m\")\n",
    "select_random_sent(novel_tags_better, 3)\n",
    "print()\n",
    "\n",
    "print(\"========== Contractions ==========\")\n",
    "print(\"Example 2: 'll in you'll incorrectly tagged. Corrected by improved tagger: \")\n",
    "novel_tags_better = get_tag_novel(novel_sents, brown_and_novel_tagger, \"'ll\")\n",
    "select_random_sent(novel_tags_better, 3)\n",
    "print()\n",
    "\n",
    "print(\"========== Past Tense as Noun ==========\")\n",
    "print(\"Thought in Thought Process incorrectly tagged. Corrected by improved tagger: \")\n",
    "novel_tags_better = get_tag_novel(novel_sents, brown_and_novel_tagger, \"Thought\")\n",
    "select_random_sent(novel_tags_better, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked quite well.  It would be worth experimenting to see if it would still work if I'd supplied fewer of the cooking verbs.\n",
    "\n",
    "> YC: I noticed that even though only examples of \"she'll\" and \"you'll\" are given, the tagger handles \"they'll\" and \"there'll\" equally well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: ##\n",
    "\n",
    "Rewrite this notebook to do the following:\n",
    "- Tag your adopted text with an NLTK backoff tagger\n",
    "- Identify a common type of error that is amenable to fixing by making a pattern of training data, similar to what we see with the recipe examples.  You'll want to focus on a particular pattern so that making a few tweaks will have a impact on the results of training.\n",
    "- Show the before and after effects on the output of the tagger.  Ideally you'll see the errors get fixed not just on the specific examples you fixed, but on similar examples with different words.  In the case of recipes, imperative verbs beyond those in the hardcoded list would be fixed because the tagger would recognize the pattern that verbs can occur at the start of the sentence."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
